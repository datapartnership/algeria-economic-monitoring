{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ALGERIA POPULATION-WEIGHTED SPEED ANALYSIS (dtype-safe & memory-safe) ---\n",
    "\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "from shapely import wkt\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Paths\n",
    "GRID_WKT     = \"processed_data/algeria_grid_z12_wkt.csv\"\n",
    "GRID_LONG    = \"processed_data/algeria_grid_data_long_z12_mobile.csv\"\n",
    "WORLDPOP_DIR = \"worldpop_tifs/\"\n",
    "OUT_CSV      = \"processed_data/algeria_pop_weighted_trends_2019_2025.csv\"\n",
    "\n",
    "YEARS = list(range(2019, 2026))  #\n",
    "CHUNK_SIZE = 2500\n",
    "POP_TMP_CSV = \"processed_data/_tmp_pop_by_tile_year.csv\"\n",
    "\n",
    "g_tiles = pd.read_csv(GRID_WKT, dtype={\"quadkey_z12\": str})\n",
    "if \"quadkey_z12\" not in g_tiles.columns:\n",
    "    g_tiles[\"quadkey_z12\"] = g_tiles[\"quadkey\"].astype(str)\n",
    "g_tiles[\"geometry\"] = g_tiles[\"wkt\"].apply(wkt.loads)\n",
    "g_tiles = gpd.GeoDataFrame(g_tiles[[\"quadkey_z12\", \"geometry\"]], geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "df_long = pd.read_csv(GRID_LONG, encoding=\"utf-8\", dtype={\"quadkey_z12\": str})\n",
    "if \"year\" not in df_long.columns and \"date\" in df_long.columns:\n",
    "    df_long[\"year\"] = df_long[\"date\"].astype(str).str[:4].astype(int)\n",
    "df_long = df_long[df_long[\"year\"].between(min(YEARS), max(YEARS))]\n",
    "\n",
    "tile_year = (\n",
    "    df_long.groupby([\"quadkey_z12\", \"year\"], as_index=False)\n",
    "           .agg(download=(\"avg_download_mbps\", \"mean\"),\n",
    "                upload=(\"avg_upload_mbps\", \"mean\"))\n",
    ")\n",
    "\n",
    "tifs = sorted(glob.glob(os.path.join(WORLDPOP_DIR, \"*.tif\")))\n",
    "\n",
    "def infer_year(path):\n",
    "    m = re.search(r\"(20\\d{2})\", os.path.basename(path))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "year_to_tif = {infer_year(fp): fp for fp in tifs if infer_year(fp) in YEARS}\n",
    "\n",
    "os.makedirs(os.path.dirname(POP_TMP_CSV), exist_ok=True)\n",
    "if os.path.exists(POP_TMP_CSV):\n",
    "    os.remove(POP_TMP_CSV)\n",
    "\n",
    "tiles_cache = {}\n",
    "\n",
    "for y in YEARS:\n",
    "    tif = year_to_tif.get(y)\n",
    "    if tif is None:\n",
    "        print(f\"⚠ Missing WorldPop raster for {y}\")\n",
    "        continue\n",
    "\n",
    "    with rasterio.Env(GDAL_CACHEMAX=128):\n",
    "        with rasterio.open(tif) as src:\n",
    "            crs_key = str(src.crs)\n",
    "\n",
    "            if crs_key not in tiles_cache:\n",
    "                tp = g_tiles.to_crs(src.crs).copy()\n",
    "                rbox = box(*src.bounds)\n",
    "                try:\n",
    "                    sidx = tp.sindex\n",
    "                    cand_idx = list(sidx.intersection(rbox.bounds))\n",
    "                    tp = tp.iloc[cand_idx]\n",
    "                except Exception:\n",
    "                    pass\n",
    "                tp = tp[tp.intersects(rbox)].reset_index(drop=True)\n",
    "                tiles_cache[crs_key] = tp[[\"quadkey_z12\", \"geometry\"]]\n",
    "\n",
    "            tiles_proj = tiles_cache[crs_key]\n",
    "\n",
    "            if tiles_proj.empty:\n",
    "                print(f\"⚠ No overlapping tiles for {y}\")\n",
    "                continue\n",
    "\n",
    "            n = len(tiles_proj)\n",
    "            for start in range(0, n, CHUNK_SIZE):\n",
    "                end = min(start + CHUNK_SIZE, n)\n",
    "                sub = tiles_proj.iloc[start:end]\n",
    "\n",
    "                zs = zonal_stats(\n",
    "                    list(sub[\"geometry\"]),\n",
    "                    tif,\n",
    "                    stats=[\"sum\"],\n",
    "                    nodata=(src.nodata if src.nodata is not None else None),\n",
    "                    all_touched=True\n",
    "                )\n",
    "                pop = np.fromiter((d[\"sum\"] if (d[\"sum\"] is not None) else 0.0 for d in zs), dtype=np.float64)\n",
    "\n",
    "                out_chunk = pd.DataFrame({\n",
    "                    \"quadkey_z12\": sub[\"quadkey_z12\"].astype(str).values,\n",
    "                    \"year\": y,\n",
    "                    \"pop\": pop\n",
    "                })\n",
    "\n",
    "                write_header = not os.path.exists(POP_TMP_CSV)\n",
    "                out_chunk.to_csv(POP_TMP_CSV, mode=\"a\", header=write_header, index=False, encoding=\"utf-8\")\n",
    "                del out_chunk, pop, zs\n",
    "            import gc; gc.collect()\n",
    "\n",
    "pop_by_tile_year = pd.read_csv(POP_TMP_CSV, dtype={\"quadkey_z12\": str, \"year\": int})\n",
    "\n",
    "tile_year[\"quadkey_z12\"] = tile_year[\"quadkey_z12\"].astype(str)\n",
    "tile_year[\"year\"] = tile_year[\"year\"].astype(int)\n",
    "pop_by_tile_year[\"quadkey_z12\"] = pop_by_tile_year[\"quadkey_z12\"].astype(str)\n",
    "pop_by_tile_year[\"year\"] = pop_by_tile_year[\"year\"].astype(int)\n",
    "\n",
    "tile_year[\"quadkey_z12\"] = tile_year[\"quadkey_z12\"].str.strip()\n",
    "pop_by_tile_year[\"quadkey_z12\"] = pop_by_tile_year[\"quadkey_z12\"].str.strip()\n",
    "\n",
    "df_m = (tile_year.merge(pop_by_tile_year, on=[\"quadkey_z12\", \"year\"], how=\"left\")\n",
    "                 .fillna({\"pop\": 0.0}))\n",
    "\n",
    "def weighted_average(group, col, wcol=\"pop\"):\n",
    "    valid = group[[col, wcol]].notna().all(axis=1)\n",
    "    group_valid = group[valid]\n",
    "\n",
    "    if len(group_valid) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    w = group_valid[wcol].clip(lower=0)\n",
    "    v = group_valid[col]\n",
    "\n",
    "    total_weight = w.sum()\n",
    "    if total_weight == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return (v * w).sum() / total_weight\n",
    "\n",
    "nat = (\n",
    "    df_m.groupby(\"year\", as_index=False)\n",
    "        .apply(lambda g: pd.Series({\n",
    "            \"pw_download_mbps\": weighted_average(g, \"download\"),\n",
    "            \"pw_upload_mbps\":   weighted_average(g, \"upload\")\n",
    "        }))\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values(\"year\")\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "nat.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "print(nat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algeria_economic_monitoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
